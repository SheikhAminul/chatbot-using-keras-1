{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import preprocessing, utils, losses, layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "from pickle import dump, load\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data & Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conversation_data(data_directory):\n",
    "    fileList = os.listdir(data_directory + \"/\")\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for file in fileList:\n",
    "        data = yaml.safe_load(open(data_directory + \"/\" + file, \"rb\"))\n",
    "        conversation_list = data[\"conversations\"]\n",
    "        for conversation in conversation_list:\n",
    "            for i in range(len(conversation) - 1):\n",
    "                questions.append(conversation[i])\n",
    "                answers.append(conversation[i + 1])\n",
    "    answers_index = []\n",
    "    for i in range(len(answers)):\n",
    "        answers_index.append([i])\n",
    "    return questions, answers, np.array(answers_index)\n",
    "\n",
    "# load data from all files\n",
    "questions, answers, answers_index = load_conversation_data(\"./English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data):\n",
    "    if type(data) == str:\n",
    "       data = [data]\n",
    "    return tokenizer.texts_to_sequences(data)\n",
    "\n",
    "# define and fit tokenizer on questions\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(questions)\n",
    "\n",
    "x = pad_sequences(vectorize(questions))\n",
    "sentence_maxlen = len(x[0])\n",
    "y = pad_sequences(answers_index, maxlen=sentence_maxlen)\n",
    "vocabulary_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sheikh/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sheikh/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sheikh/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/sheikh/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sheikh/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.004474</td>\n",
       "      <td>0.002386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.001259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithm  Precision    Recall  F1 Score\n",
       "0  DecisionTreeClassifier   0.001678  0.004474  0.002386\n",
       "1      LogisticRegression   0.000840  0.002519  0.001259"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "\n",
    "models = [\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    LogisticRegression(random_state=0)\n",
    "]\n",
    "\n",
    "# Precision, Recall and F1 Score\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#For Each Algorithm \n",
    "accuracyList = []\n",
    "for model in models:\n",
    "    modelName = model.__class__.__name__\n",
    "    #Split Data \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, answers, test_size=0.33, random_state=0)\n",
    "    #Train Algorithm\n",
    "    model.fit(X_train, y_train)\n",
    "    # Make Predictions\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracyList.append([modelName, precision_score(y_test, y_pred, average='macro'), recall_score(y_test, y_pred, average='macro'), f1_score(y_test, y_pred, average='macro')])\n",
    "\n",
    "pd.DataFrame(accuracyList, columns=[\"Algorithm\", \"Precision\", \"Recall\", \"F1 Score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 128)         125312    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 30)                3870      \n",
      "=================================================================\n",
      "Total params: 260,766\n",
      "Trainable params: 260,766\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "model.add(Embedding(vocabulary_size, 128)) \n",
    "model.add(LSTM(128, dropout = 0.2, recurrent_dropout = 0.2)) \n",
    "model.add(Dense(sentence_maxlen, activation = 'sigmoid'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - 1s 121ms/step - loss: 1398.6071 - accuracy: 0.8688\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 1s 122ms/step - loss: 974.2885 - accuracy: 0.9988\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 1s 124ms/step - loss: 607.5532 - accuracy: 0.9988\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 1s 123ms/step - loss: 262.7197 - accuracy: 0.9988\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 1s 121ms/step - loss: 95.2849 - accuracy: 0.9988\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 1s 121ms/step - loss: 41.3351 - accuracy: 0.9988\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 1s 125ms/step - loss: 23.4728 - accuracy: 0.9988\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 1s 122ms/step - loss: 16.3380 - accuracy: 0.9988\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 1s 121ms/step - loss: 12.7691 - accuracy: 0.9988\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 10.6425 - accuracy: 0.9988\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 9.1812 - accuracy: 0.9988\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 8.1024 - accuracy: 0.9988\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 7.2464 - accuracy: 0.9988\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 1s 130ms/step - loss: 6.5414 - accuracy: 0.9988\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 5.9460 - accuracy: 0.9988\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 5.4412 - accuracy: 0.9988\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 1s 119ms/step - loss: 5.0034 - accuracy: 0.9988\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 4.6236 - accuracy: 0.9988\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 4.2868 - accuracy: 0.9988\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 3.9877 - accuracy: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffb1902b940>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(x,\n",
    "          y,\n",
    "          batch_size=100,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and extra files saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# save the trained model\n",
    "model.save('model.h5')\n",
    "\n",
    "# pickle the extra files\n",
    "with open('extrafiles.pkl', 'wb') as f:\n",
    "    dump([tokenizer, sentence_maxlen, answers], f)\n",
    "print('Model and extra files saved successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Saved Model and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = keras.models.load_model('model.h5')\n",
    "\n",
    "# load the extra files\n",
    "with open('extrafiles.pkl', 'rb') as f:\n",
    "    tokenizer, sentence_maxlen, answers = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n",
      " - Computers which can perform very large numbers of calculations at very high speed and accuracy are called super computers.\n",
      "Hello\n",
      " - Computers which can perform very large numbers of calculations at very high speed and accuracy are called super computers.\n",
      "How are you?\n",
      " - Computers which can perform very large numbers of calculations at very high speed and accuracy are called super computers.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_response(query):\n",
    "    pad_que = pad_sequences(vectorize(query), maxlen=30)\n",
    "    pred = model.predict(pad_que)[0]\n",
    "    answers_index = np.argmax(pred)\n",
    "    return answers[answers_index]\n",
    "\n",
    "while True:\n",
    "    input_query = input()\n",
    "    if input_query == '':\n",
    "        break\n",
    "    else:\n",
    "        print(' - ' + get_response(input_query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
