{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import preprocessing, utils, losses, layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "from pickle import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data & Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conversation_data(data_directory):\n",
    "    fileList = os.listdir(data_directory + \"/\")\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for file in fileList:\n",
    "        data = yaml.safe_load(open(data_directory + \"/\" + file, \"rb\"))\n",
    "        conversation_list = data[\"conversations\"]\n",
    "        for conversation in conversation_list:\n",
    "            for i in range(len(conversation) - 1):\n",
    "                questions.append(conversation[i])\n",
    "                answers.append(conversation[i +1])\n",
    "    answers_index = []\n",
    "    for i in range(len(answers)):\n",
    "        answers_index.append(i)\n",
    "    return questions, answers, np.array(answers_index)\n",
    "\n",
    "# load data from all files\n",
    "questions, answers, answers_index = load_conversation_data(\"./English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data):\n",
    "    if type(data) == str:\n",
    "       data = [data]\n",
    "    return tokenizer.texts_to_matrix(data, mode='tfidf')\n",
    "\n",
    "def devectorize(data):\n",
    "    return answers[np.argmax(data)]\n",
    "\n",
    "# define and fit tokenizer on questions\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(questions)\n",
    "\n",
    "# define vocabulary size (total number of words)\n",
    "vocabulary_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "x_train = vectorize(questions)\n",
    "x_test = vectorize(questions)\n",
    "y_train = answers_index\n",
    "y_test = answers_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               501760    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 869)               445797    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 869)               0         \n",
      "=================================================================\n",
      "Total params: 1,210,213\n",
      "Trainable params: 1,210,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define and compile the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(vocabulary_size,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(len(y_train)))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 782 samples, validate on 87 samples\n",
      "Epoch 1/30\n",
      "782/782 [==============================] - 1s 793us/sample - loss: 6.8336 - accuracy: 0.0000e+00 - val_loss: 6.8921 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "782/782 [==============================] - 0s 227us/sample - loss: 6.5371 - accuracy: 0.0435 - val_loss: 7.0827 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "782/782 [==============================] - 0s 233us/sample - loss: 6.2288 - accuracy: 0.1688 - val_loss: 7.5135 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "782/782 [==============================] - 0s 249us/sample - loss: 5.7294 - accuracy: 0.2928 - val_loss: 8.4034 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "782/782 [==============================] - 0s 377us/sample - loss: 5.1455 - accuracy: 0.3951 - val_loss: 9.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "782/782 [==============================] - 0s 237us/sample - loss: 4.4684 - accuracy: 0.5192 - val_loss: 10.6584 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "782/782 [==============================] - 0s 412us/sample - loss: 3.8123 - accuracy: 0.5985 - val_loss: 11.3670 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "782/782 [==============================] - 0s 346us/sample - loss: 3.1429 - accuracy: 0.6650 - val_loss: 11.9412 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "782/782 [==============================] - 0s 257us/sample - loss: 2.5348 - accuracy: 0.6777 - val_loss: 12.4914 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "782/782 [==============================] - 0s 240us/sample - loss: 1.9911 - accuracy: 0.7020 - val_loss: 12.9237 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "782/782 [==============================] - 0s 238us/sample - loss: 1.5634 - accuracy: 0.7238 - val_loss: 13.2392 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "782/782 [==============================] - 0s 298us/sample - loss: 1.3270 - accuracy: 0.7110 - val_loss: 13.4726 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "782/782 [==============================] - 0s 247us/sample - loss: 1.1308 - accuracy: 0.7212 - val_loss: 13.5710 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "782/782 [==============================] - 0s 234us/sample - loss: 1.0133 - accuracy: 0.7148 - val_loss: 13.5331 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "782/782 [==============================] - 0s 254us/sample - loss: 0.9246 - accuracy: 0.7327 - val_loss: 13.5085 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "782/782 [==============================] - 0s 276us/sample - loss: 0.8627 - accuracy: 0.7481 - val_loss: 13.4584 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "782/782 [==============================] - 0s 234us/sample - loss: 0.8269 - accuracy: 0.7481 - val_loss: 13.4010 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "782/782 [==============================] - 0s 228us/sample - loss: 0.8058 - accuracy: 0.7391 - val_loss: 13.4234 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "782/782 [==============================] - 0s 262us/sample - loss: 0.7496 - accuracy: 0.7545 - val_loss: 13.4237 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "782/782 [==============================] - 0s 237us/sample - loss: 0.7487 - accuracy: 0.7558 - val_loss: 13.4195 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "782/782 [==============================] - 0s 240us/sample - loss: 0.7458 - accuracy: 0.7442 - val_loss: 13.3730 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "782/782 [==============================] - 0s 256us/sample - loss: 0.7067 - accuracy: 0.7596 - val_loss: 13.3559 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "782/782 [==============================] - 0s 258us/sample - loss: 0.7047 - accuracy: 0.7634 - val_loss: 13.3085 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "782/782 [==============================] - 0s 235us/sample - loss: 0.7057 - accuracy: 0.7430 - val_loss: 13.2961 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "782/782 [==============================] - 0s 364us/sample - loss: 0.7018 - accuracy: 0.7570 - val_loss: 13.2821 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "782/782 [==============================] - 0s 245us/sample - loss: 0.6838 - accuracy: 0.7545 - val_loss: 13.2682 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "782/782 [==============================] - 0s 409us/sample - loss: 0.6896 - accuracy: 0.7583 - val_loss: 13.2329 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "782/782 [==============================] - 0s 296us/sample - loss: 0.6551 - accuracy: 0.7864 - val_loss: 13.2191 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "782/782 [==============================] - 0s 355us/sample - loss: 0.6693 - accuracy: 0.7673 - val_loss: 13.2197 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "782/782 [==============================] - 0s 293us/sample - loss: 0.6713 - accuracy: 0.7609 - val_loss: 13.1590 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffb54563110>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(x_train, y_train,\n",
    "                    batch_size=100,\n",
    "                    epochs=30,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and extra files saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# save the trained model\n",
    "model.save('model.h5')\n",
    "\n",
    "# pickle the extra files\n",
    "with open('extrafiles.pkl', 'wb') as f:\n",
    "    dump([tokenizer, answers], f)\n",
    "print('Model and extra files saved successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Saved Model and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = keras.models.load_model('model.h5')\n",
    "\n",
    "# load the extra files\n",
    "with open('extrafiles.pkl', 'rb') as f:\n",
    "    tokenizer, answers = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(query):\n",
    "    return devectorize(model.predict(vectorize(query)))\n",
    "\n",
    "while True:\n",
    "    input_query = input()\n",
    "    if input_query == '':\n",
    "        break\n",
    "    else:\n",
    "        print(' - ' + get_response(input_query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
